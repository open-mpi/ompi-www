<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Hardware Locality (hwloc): Topology Attributes: Distances, Memory Attributes and CPU Kinds</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Hardware Locality (hwloc)<span id="projectnumber">&#160;2.13.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search',true);
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('topoattrs.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">Topology Attributes: Distances, Memory Attributes and CPU Kinds </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Besides the hierarchy of objects and individual object attributes (see <a class="el" href="attributes.html">Object attributes</a>), hwloc may also expose finer information about the hardware organization.</p>
<h1 class="doxsection"><a class="anchor" id="topoattrs_distances"></a>
Distances</h1>
<p>A machine with 4 CPUs may have identical links between every pairs of CPUs, or those CPUs could also only be connected through a ring. In the ring case, accessing the memory of nearby CPUs is slower than local memory, but it is also faster than accessing the memory of CPU on the opposite side of the ring. These deep details cannot be exposed in the hwloc hierarchy, that is why hwloc also exposes distances.</p>
<p>Distances are matrices of values between sets of objects, usually latencies or bandwidths. By default, hwloc tries to get a matrix of relative latencies between NUMA nodes when exposed by the hardware.</p>
<p>In the aforementioned ring case, the matrix could report 10 for latency between a NUMA node and itself, 20 for nearby nodes, and 30 for nodes that are opposites on the ring. Those are theoretical values exposed by hardware vendors (in the System Locality Distance Information Table (SLIT) in the ACPI) rather than physical latencies. They are mostly meant for comparing node relative distances.</p>
<p>Distances structures currently created by hwloc are: </p><dl>
<dt>NUMALatency (Linux, Solaris, FreeBSD) </dt>
<dd>This is the matrix of theoretical latencies described above.  </dd>
<dt>XGMIBandwidth (RSMI) </dt>
<dd><p class="startdd">This is the matrix of unidirectional XGMI bandwidths between AMD GPUs (in MB/s). It contains 0 when there is no direct XGMI link between objects. Values on the diagonal are artificially set to very high so that local access always appears faster than remote access.</p>
<p class="interdd">GPUs are identified by RSMI OS devices such as "rsmi0". They may be converted into the corresponding OpenCL or PCI devices using <a class="el" href="group__hwlocality__helper__find__misc.html#gab5df3ad1e8565ea0c2cf06412f6f6233" title="Return an object of a different type with same locality.">hwloc_get_obj_with_same_locality()</a> or the hwloc-annotate tool.</p>
<p class="enddd"><a class="el" href="group__hwlocality__distances__get.html#gabcadd041f3072999d68f2d94e38670f7" title="Apply a transformation to a distances structure.">hwloc_distances_transform()</a> or hwloc-annotate may also be used to transform this matrix into something more convenient, for instance by replacing bandwidths with numbers of links between peers.  </p>
</dd>
<dt>XGMIHops (RSMI) </dt>
<dd>This matrix lists the number of XGMI hops between AMD GPUs. It reports 1 when there is a direct link between two distinct GPUs. If there is no XGMI route between them, the value is 0. The number of hops between a GPU and itself (on the diagonal) is 0 as well.  </dd>
<dt>XeLinkBandwidth (LevelZero) </dt>
<dd><p class="startdd">This is the matrix of unidirectional XeLink bandwidths between Intel GPUs (in MB/s). It contains 0 when there is no direct XeLink between objects. When there are multiple links, their bandwidth is aggregated.</p>
<p class="interdd">Values on the diagonal are artificially set to very high so that local access always appears faster than remote access. This includes bandwidths between a (sub)device and itself, between a subdevice and its parent device, or between two subdevices of the same parent.</p>
<p class="interdd">The matrix interconnects all LevelZero devices and subdevices (if any), even if some of them may have no link at all.</p>
<p class="enddd">The bandwidths of links between subdevices are accumulated in the bandwidth between their parents.  </p>
</dd>
<dt>NVLinkBandwidth (NVML) </dt>
<dd><p class="startdd">This is the matrix of unidirectional NVLink bandwidths between NVIDIA GPUs (in MB/s). It contains 0 when there is no direct NVLink between objects. When there are multiple links, their bandwidth is aggregated. Values on the diagonal are artificially set to very high so that local access always appears faster than remote access.</p>
<p class="interdd">On POWER platforms, NVLinks may also connects GPUs to CPUs. On NVIDIA platforms such as DGX-2, a NVSwitch may interconnect GPUs through NVLinks. In these cases, the distances structure is heterogeneous. GPUs always appear first in the matrix (as NVML OS devices such as "nvml0"), and non-GPU objects may appear at the end (Package for POWER processors, PCI device for NVSwitch).</p>
<p class="interdd">NVML OS devices may be converted into the corresponding CUDA, OpenCL or PCI devices using <a class="el" href="group__hwlocality__helper__find__misc.html#gab5df3ad1e8565ea0c2cf06412f6f6233" title="Return an object of a different type with same locality.">hwloc_get_obj_with_same_locality()</a> or the hwloc-annotate tool.</p>
<p class="interdd"><a class="el" href="group__hwlocality__distances__get.html#gabcadd041f3072999d68f2d94e38670f7" title="Apply a transformation to a distances structure.">hwloc_distances_transform()</a> or hwloc-annotate may also be used to transform this matrix into something more convenient, for instance by removing switches or CPU ports, or by replacing bandwidths with numbers of links between peers.</p>
<p class="enddd">When a NVSwitch interconnects GPUs, only links between one GPU and different NVSwitch ports are reported. They may be merged into a single switch port with <a class="el" href="group__hwlocality__distances__get.html#gabcadd041f3072999d68f2d94e38670f7" title="Apply a transformation to a distances structure.">hwloc_distances_transform()</a> or hwloc-annotate. Or a transitive closure may also be applied to report the bandwidth between GPUs across the NVSwitch. </p>
</dd>
</dl>
<p>Users may also specify their own matrices between any set of objects, even if these objects are of different types (e.g. bandwidths between GPUs and CPUs).</p>
<p>The entire API is located in <a class="el" href="distances_8h_source.html">hwloc/distances.h</a>. See also <a class="el" href="group__hwlocality__distances__get.html">Retrieve distances between objects</a>, as well as <a class="el" href="group__hwlocality__distances__consult.html">Helpers for consulting distance matrices</a> and <a class="el" href="group__hwlocality__distances__add.html">Add distances between objects</a>.</p>
<h1 class="doxsection"><a class="anchor" id="topoattrs_memattrs"></a>
Memory Attributes</h1>
<p>Machines with heterogeneous memory, for instance high-bandwidth memory (HBM), normal memory (DDR), and/or high-capacity slow memory (such as non-volatile memory DIMMs, NVDIMMs) require applications to allocate buffers in the appropriate target memory depending on performance and capacity needs. Those target nodes may be exposed in the hwloc hierarchy as different memory children but there is a need for performance information to select the appropriate one.</p>
<p>hwloc memory attributes are designed to expose memory information such as latency, bandwidth, etc. Users may also specify their own attributes and values.</p>
<p>The memory attributes API is located in <a class="el" href="memattrs_8h_source.html">hwloc/memattrs.h</a>, see <a class="el" href="group__hwlocality__memattrs.html">Comparing memory node attributes for finding where to allocate on</a> and <a class="el" href="group__hwlocality__memattrs__manage.html">Managing memory attributes</a> for details. See also an example in doc/examples/memory-attributes.c in the source tree.</p>
<p>Memory attributes are the low-level solution to selecting target memory. hwloc uses them internally to build Memory Tiers which provide an easy way to distinguish NUMA nodes of different kinds, as explained in <a class="el" href="heteromem.html">Heterogeneous Memory</a>.</p>
<h1 class="doxsection"><a class="anchor" id="topoattrs_cpukinds"></a>
CPU Kinds</h1>
<p>Hybrid CPUs may contain different kinds of cores. The CPU kinds API in <a class="el" href="cpukinds_8h_source.html">hwloc/cpukinds.h</a> provides a way to list the sets of PUs in each kind and get some optional information about their hardware characteristics and efficiency.</p>
<p>If the operating system provides efficiency information (e.g. Windows 10, MacOS X / Darwin and some Linux kernels), it is used to rank hwloc CPU kinds by efficiency. Otherwise, hwloc implements several heuristics based on frequencies and core types (see HWLOC_CPUKINDS_RANKING in <a class="el" href="envvar.html#envvar_heuristics">Environment variables for tweaking hwloc heuristics</a>).</p>
<p>The ranking shows energy-efficient CPUs first, and high-performance power-hungry cores last.</p>
<p>These CPU kinds may be annotated with the following native attributes: </p><dl>
<dt>FrequencyMaxMHz (Linux) </dt>
<dd>The maximal operating frequency of the core, as reported by <span class="tt">cpufreq</span> drivers on Linux.  </dd>
<dt>FrequencyBaseMHz (Linux) </dt>
<dd>The base/nominal operating frequency of the core, as reported by some <span class="tt">cpufreq</span> or ACPI drivers on Linux (e.g. <span class="tt">cpufreq_cppc</span> or <span class="tt">intel_pstate</span>).  </dd>
<dt>CoreType (x86) </dt>
<dd>A string describing the kind of core, currently <span class="tt">IntelAtom</span>, <span class="tt">IntelCore</span> or <span class="tt">IntelLowPower</span>, as reported by the x86 CPUID instruction and Linux PMU on some Intel processors.  </dd>
<dt>LinuxCapacity (Linux) </dt>
<dd>The Linux-specific CPU capacity found in sysfs, as reported by the Linux kernel on some recent platforms. Higher values usually mean that the Linux scheduler considers the core as high-performance rather than energy-efficient.  </dd>
<dt>LinuxCPUType (Linux) </dt>
<dd>The Linux-specific CPU type found in sysfs, such as <span class="tt">intel_atom_0</span>, as reported by future Linux kernels on some Intel processors.  </dd>
<dt>DarwinCompatible (Darwin / Mac OS X) </dt>
<dd>The compatibility attribute of the CPUs as found in the IO registry on Darwin / Mac OS X. For instance <span class="tt">apple,icestorm;ARM,v8</span> for energy-efficient cores and <span class="tt">apple,firestorm;ARM,v8</span> on performance cores on Apple M1 CPU.  </dd>
</dl>
<p>The hwloc-calc tool may be used to query the number of cpukinds or which ones exist in some cores: </p><pre class="fragment">$ hwloc-calc -N cpukind all
2
$ hwloc-calc -I cpukind package:0
0,1
</pre><p>See <a class="el" href="group__hwlocality__cpukinds.html">Kinds of CPU cores</a> for details. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
