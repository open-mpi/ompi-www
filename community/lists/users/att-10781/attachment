<html>
<head>
<style><!--
.hmmessage P
{
margin:0px;
padding:0px
}
body.hmmessage
{
font-size: 10pt;
font-family:Verdana
}
--></style>
</head>
<body class='hmmessage'>
Hi Loh,<BR>
I used MPI_Init_thread(&amp;argc,&amp;argv, MPI_THREAD_MULTIPLE, &amp;provided); in my program and got provided = 0 which turns out to be the MPI_THREAD_SINGLE. Does this mean that I can not use MPI_THREAD_MULTIPLE model? I write a little program to test the multithreading and it worked sometimes and failed sometimes. It also hang&nbsp;there sometimes.&nbsp;Does this only because the MPI_THREAD_MULTIPLE is not supported or&nbsp;there are some bugs in the program? I attached the little program as follow:<BR>
&nbsp;<BR>
#include &lt;iostream&gt;<BR>#include &lt;pthread.h&gt;<BR>#include &lt;fstream&gt;<BR>#include &lt;sstream&gt;<BR>#include &lt;string.h&gt;<BR>#include "mpi.h"<BR>using namespace std;<BR>#define MSG_QUERY_SIZE 16&nbsp; //sizeof(MPI_query_msg) = 16<BR>
struct MPI_query_msg<BR>{<BR>&nbsp;int flag;&nbsp;&nbsp; // -1:request cell; 0:query coordinate; 1:there is no cell to grant<BR>&nbsp;int x;<BR>&nbsp;int y;<BR>&nbsp;int ignited;&nbsp;&nbsp; // if x,y are not negative, then ignited: 0 is not ignited, 1 is ignited<BR>};<BR>
void* backRecv(void* arg)<BR>{<BR>&nbsp;int myid, nprocs;<BR>&nbsp;pthread_mutex_init(&amp;_dealmutex2, NULL);<BR>&nbsp;stringstream RANK;<BR>&nbsp;MPI_Status status;<BR>&nbsp;MPI_Request&nbsp; req2;<BR>&nbsp;MPI_Comm_rank(MPI_COMM_WORLD, &amp;myid);<BR>&nbsp;MPI_Comm_size(MPI_COMM_WORLD, &amp;nprocs);<BR>&nbsp;int left = (myid - 1 + nprocs - 1) % (nprocs - 1);<BR>&nbsp;int right = (myid + 1) % (nprocs - 1);<BR>&nbsp;MPI_query_msg rMSG;<BR>&nbsp;RANK &lt;&lt; myid;<BR>&nbsp;cout &lt;&lt; myid &lt;&lt; " create background message recv" &lt;&lt; endl;<BR>&nbsp;int x, y;<BR>&nbsp;//char c;<BR>&nbsp;int m;<BR>&nbsp;int count = 0;<BR>&nbsp;string filename("f_");<BR>&nbsp;filename += RANK.str();<BR>&nbsp;filename += "_backRecv.txt";<BR>&nbsp;fstream fout(filename.c_str(), ios::out);<BR>&nbsp;if(!fout)<BR>&nbsp;{<BR>&nbsp;&nbsp;cout &lt;&lt; "can not create the file " &lt;&lt; filename &lt;&lt; endl;<BR>&nbsp;&nbsp;fout.close();<BR>&nbsp;&nbsp;exit(1);<BR>&nbsp;}<BR>
&nbsp;while(true)<BR>&nbsp;{<BR>&nbsp;&nbsp;MPI_Recv(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, MPI_ANY_SOURCE, 222, MPI_COMM_WORLD, &amp;status);<BR>&nbsp;&nbsp;//MPI_Irecv(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, MPI_ANY_SOURCE, 222, MPI_COMM_WORLD, &amp;req2);<BR>&nbsp;&nbsp;//MPI_Wait(&amp;req2, &amp;status);<BR>&nbsp;&nbsp;fout &lt;&lt; "BACKREV:" &lt;&lt; myid &lt;&lt; " recv from " &lt;&lt; status.MPI_SOURCE &lt;&lt; " rMSG.flag = " &lt;&lt; rMSG.flag &lt;&lt; " with tag 222" &lt;&lt; endl;<BR>&nbsp;&nbsp;fout.flush();<BR>&nbsp;&nbsp;if(rMSG.flag == -1)<BR>&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;fout &lt;&lt; "*******backRecv FINISHED IN " &lt;&lt; myid &lt;&lt; "********" &lt;&lt; endl;<BR>&nbsp;&nbsp;&nbsp;fout.flush();<BR>&nbsp;&nbsp;&nbsp;fout.close();<BR>&nbsp;&nbsp;&nbsp;pthread_exit(NULL);<BR>&nbsp;&nbsp;&nbsp;return 0;<BR>&nbsp;&nbsp;}&nbsp;<BR>&nbsp;};<BR>}<BR>
int main(int argc, char **argv) <BR>{<BR>&nbsp;int myid = 0;<BR>&nbsp;int provided;<BR>&nbsp;int nprocs = 0;<BR>&nbsp;pthread_t pt1 = 0;<BR>&nbsp;&nbsp;&nbsp; pthread_t pt2 = 0;;<BR>&nbsp;int pret1 = 0;<BR>&nbsp;int pret2 = 0;<BR>&nbsp;int i = 0, j = 0, m = 0;<BR>&nbsp;//MPI_Status status;<BR>&nbsp;MPI_Request&nbsp; requ1, requ2;<BR>&nbsp;MPI_Status status1, status2;<BR>&nbsp;<BR>&nbsp;MPI_Init_thread(&amp;argc,&amp;argv, MPI_THREAD_MULTIPLE, &amp;provided);<BR>&nbsp;//MPI_Init(&amp;argc,&amp;argv);<BR>&nbsp; &nbsp;MPI_Comm_size(MPI_COMM_WORLD,&amp;nprocs);<BR>&nbsp; &nbsp;MPI_Comm_rank(MPI_COMM_WORLD,&amp;myid); <BR>&nbsp;pthread_mutex_init(&amp;_dealmutex, NULL);<BR>&nbsp;<BR>&nbsp;if(myid == nprocs - 1)&nbsp; // the last one<BR>&nbsp;{<BR>&nbsp;&nbsp;if(provided == MPI_THREAD_MULTIPLE)<BR>&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; myid &lt;&lt; " got MPI_THREAD_MULTIPLE " &lt;&lt; endl;<BR>&nbsp;&nbsp;}<BR>&nbsp;&nbsp;else<BR>&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; myid &lt;&lt; " MPI_THREAD_MULTIPLE = " &lt;&lt; MPI_THREAD_MULTIPLE &lt;&lt; endl;<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; myid &lt;&lt; " MPI_THREAD_SINGLE = " &lt;&lt; MPI_THREAD_SINGLE &lt;&lt; endl;<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; myid &lt;&lt; " got provided = " &lt;&lt; provided &lt;&lt; endl;<BR>&nbsp;&nbsp;}<BR>&nbsp;&nbsp;MPI_query_msg sMSGqueue[50], rMSG;<BR>&nbsp;&nbsp;for(i=0; i&lt;50; i++)<BR>&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;sMSGqueue[i].flag = i;<BR>&nbsp;&nbsp;&nbsp;sMSGqueue[i].x = i;<BR>&nbsp;&nbsp;&nbsp;sMSGqueue[i].y = i;<BR>&nbsp;&nbsp;&nbsp;sMSGqueue[i].ignited = i;<BR>&nbsp;&nbsp;}<BR>&nbsp;&nbsp;while(j &lt; 50)<BR>&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;MPI_Recv(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &amp;status2);<BR>&nbsp;&nbsp;&nbsp;//MPI_Irecv(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &amp;requ2);<BR>&nbsp;&nbsp;&nbsp;//MPI_Wait(&amp;requ2, &amp;status2);<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; "MAIN(" &lt;&lt; j &lt;&lt; "): " &lt;&
lt; myid &lt;&lt; " recvs from "&lt;&lt; status2.MPI_SOURCE &lt;&lt; " with tag = " &lt;&lt; status2.MPI_TAG &lt;&lt; " rMSG.flag = " &lt;&lt; rMSG.flag &lt;&lt; endl;<BR>
&nbsp;&nbsp;&nbsp;MPI_Send(&amp;(sMSGqueue[j]), MSG_QUERY_SIZE, MPI_CHAR, status2.MPI_SOURCE, status2.MPI_TAG, MPI_COMM_WORLD);<BR>&nbsp;&nbsp;&nbsp;//MPI_Isend(&amp;(sMSGqueue[j]), MSG_QUERY_SIZE, MPI_CHAR, status2.MPI_SOURCE, status2.MPI_TAG, MPI_COMM_WORLD, &amp;requ1);<BR>&nbsp;&nbsp;&nbsp;//MPI_Wait(&amp;requ1, &amp;status1);<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; "MAIN(" &lt;&lt; j &lt;&lt; "): " &lt;&lt; myid &lt;&lt; " sends to "&lt;&lt; status2.MPI_SOURCE &lt;&lt; " with tag = " &lt;&lt; status2.MPI_TAG &lt;&lt; " sMSGqueue[j].flag = " &lt;&lt; sMSGqueue[j].flag &lt;&lt; endl;<BR>&nbsp;&nbsp;&nbsp;j++;<BR>&nbsp;&nbsp;};<BR>&nbsp;&nbsp;int count = 0;<BR>&nbsp;&nbsp;while(true)<BR>&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;MPI_Recv(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &amp;status2);<BR>&nbsp;&nbsp;&nbsp;//MPI_Irecv(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &amp;requ2);<BR>&nbsp;&nbsp;&nbsp;//MPI_Wait(&amp;requ2, &amp;status2);<BR>&nbsp;&nbsp;&nbsp;rMSG.flag = -1;<BR>&nbsp;&nbsp;&nbsp;MPI_Send(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, status2.MPI_SOURCE, status2.MPI_TAG, MPI_COMM_WORLD);<BR>&nbsp;&nbsp;&nbsp;//MPI_Isend(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, status2.MPI_SOURCE, status2.MPI_TAG, MPI_COMM_WORLD, &amp;requ1);<BR>&nbsp;&nbsp;&nbsp;//MPI_Wait(&amp;requ1, &amp;status1);<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; "MAIN sends termination to " &lt;&lt; status2.MPI_SOURCE &lt;&lt; endl;<BR>&nbsp;&nbsp;&nbsp;count++;<BR>&nbsp;&nbsp;&nbsp;if(count == myid)<BR>&nbsp;&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;};<BR>&nbsp;&nbsp;cout &lt;&lt; "*******************************MAIN SUCESS!" &lt;&lt; endl;<BR>&nbsp;}<BR>&nbsp;else<BR>&nbsp;{<BR>&nbsp;&nbsp;pret1 = pthread_create(&amp;pt1, NULL, backRecv, NULL);<BR>&nbsp;&nbsp;if(pret1 != 0)<BR>&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; myid &lt;&lt; "backRecv Thread Create Failed." &lt;&lt; endl;<BR>&nbsp;&nbsp;&nbsp;exit(1);<BR>&nbsp;&nbsp;}<BR>&nbsp;&nbsp;MPI_query_msg sMSG, rMSG;<BR>&nbsp;&nbsp;r
MSG.flag = myid;<BR>&nbsp;&nbsp;rMSG.x = myid;<BR>&nbsp;&nbsp;rMSG.y = myid;<BR>&nbsp;&nbsp;rMSG.ignited = myid;<BR>&nbsp;&nbsp;sMSG.flag = myid;<BR>&nbsp;&nbsp;sMSG.x = myid;<BR>&nbsp;&nbsp;sMSG.y = myid;<BR>&nbsp;&nbsp;sMSG.ignited = myid;<BR>&nbsp;&nbsp;int left = (myid - 1 + nprocs - 1) % (nprocs - 1);<BR>&nbsp;&nbsp;int right = (myid + 1) % (nprocs - 1);<BR>&nbsp;&nbsp;while(true)<BR>&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;MPI_Send(&amp;sMSG, MSG_QUERY_SIZE, MPI_CHAR, nprocs-1, myid, MPI_COMM_WORLD);<BR>&nbsp;&nbsp;&nbsp;//MPI_Isend(&amp;sMSG, MSG_QUERY_SIZE, MPI_CHAR, nprocs-1, myid, MPI_COMM_WORLD, &amp;requ1);<BR>&nbsp;&nbsp;&nbsp;//MPI_Wait(&amp;requ1, &amp;status1);<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; "SLAVE: " &lt;&lt; myid &lt;&lt; " sends to "&lt;&lt; nprocs-1 &lt;&lt; " sMSG.x = " &lt;&lt; sMSG.x &lt;&lt; endl;<BR>&nbsp;&nbsp;&nbsp;MPI_Recv(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, nprocs-1, myid, MPI_COMM_WORLD, &amp;status2);<BR>&nbsp;&nbsp;&nbsp;//MPI_Irecv(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, nprocs-1, myid, MPI_COMM_WORLD, &amp;requ2);<BR>&nbsp;&nbsp;&nbsp;//MPI_Wait(&amp;requ2, &amp;status2);<BR>&nbsp;&nbsp;&nbsp;cout &lt;&lt; "SLAVE: " &lt;&lt; myid &lt;&lt; " recvs from "&lt;&lt; nprocs-1 &lt;&lt; " rMSG.flag = " &lt;&lt; rMSG.flag &lt;&lt; endl;<BR>&nbsp;&nbsp;&nbsp;MPI_Send(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, right, 222, MPI_COMM_WORLD);<BR>&nbsp;&nbsp;&nbsp;//MPI_Isend(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, right, 222, MPI_COMM_WORLD, &amp;requ1);<BR>&nbsp;&nbsp;&nbsp;//MPI_Wait(&amp;requ1, &amp;status1);<BR>
&nbsp;&nbsp;&nbsp;if(rMSG.flag == -1)<BR>&nbsp;&nbsp;&nbsp;{<BR>&nbsp;&nbsp;&nbsp;&nbsp;//MPI_Send(&amp;rMSG, MSG_QUERY_SIZE, MPI_CHAR, right, 222, MPI_COMM_WORLD);<BR>&nbsp;&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;&nbsp;}<BR>&nbsp;&nbsp;&nbsp;for(j=0; j&lt;(myid+1)*300; ++j)<BR>&nbsp;&nbsp;&nbsp;{}<BR>&nbsp;&nbsp;};<BR>&nbsp;&nbsp;cout &lt;&lt; "*******************************SLAVE" &lt;&lt; myid &lt;&lt; " SUCESS!" &lt;&lt; endl;<BR>&nbsp;&nbsp;pthread_join(pt1, NULL);<BR>&nbsp;}<BR>&nbsp;MPI_Finalize();<BR>}<BR>
&nbsp;<BR>
&nbsp;<BR>
BTW, if&nbsp;I want to create a background thread which is&nbsp;sort of&nbsp;like a deamon&nbsp;thread,&nbsp;how can I&nbsp;achieve that in&nbsp;MPI programs? Thanks.<BR>&nbsp;<BR>
<HR id=stopSpelling>
Date: Tue, 22 Sep 2009 10:32:50 -0700<BR>From: Eugene.Loh@sun.com<BR>To: users@open-mpi.org<BR>Subject: Re: [OMPI users] How to create multi-thread parallel program using thread-safe send and recv?<BR><BR>guosong wrote: 
<BLOCKQUOTE cite=midCOL102-W207D2539603EBE96410309A8DC0@phx.gbl>
<STYLE>
.ExternalClass .ecxhmmessage P
{padding:0px;}
.ExternalClass body.ecxhmmessage
{font-size:10pt;font-family:Verdana;}
</STYLE>
Thanks for responding. I&nbsp;used a&nbsp;linux cluster. I think I would like to create a model that is&nbsp;multithreaded and each&nbsp;thread can make MPI calls.&nbsp;I attached&nbsp;test code as follow. It&nbsp;has&nbsp;two pthreads and there are MPI calls&nbsp;in both of those two threads. In the main function, there&nbsp;are also&nbsp;MPI calls.&nbsp;Should I&nbsp;use a full multithreading?</BLOCKQUOTE>I guess so.&nbsp; It seems like the created threads are expected to make independent/concurrent message-passing calls.&nbsp; Do read the link I sent.&nbsp; You need to convert from MPI_Init to MPI_Init_thread(), asking for a full-multithreaded model and checking that you got it.&nbsp; Also note in main() that the MPI_Isend() calls should be matched with MPI_Wait() or similar calls.&nbsp; I guess the parent thread will sit in such calls while the child threads do their own message passing.&nbsp; Good luck.<BR> 		 	   		  <br /><hr />更多热辣资讯尽在新版MSN首页！ <a href='http://cn.msn.com/' target='_new'>立刻访问！</a></body>
</html>
