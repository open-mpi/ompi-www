<div>We can also make few different paramfiles for typical setups ( large cluster / minimum LT / max BW e.t.c )</div>
<div>the&nbsp;desired paramfile can be chosen by configure flag and be placed in <strong>$prefix/etc/openmpi-mca-params.conf</strong><br><br></div>
<div class="gmail_quote">On Sat, Jun 28, 2008 at 3:55 PM, Jeff Squyres &lt;<a href="mailto:jsquyres@cisco.com">jsquyres@cisco.com</a>&gt; wrote:<br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Agreed. &nbsp;I have a few ideas in this direction as well (random thoughts that might as well be transcribed somewhere):<br>
<br>- some kind of configure --enable-large-system (whatever) option is a Good Thing<br><br>- it would be good if the configure option simply set [MCA parameter?] defaults wherever possible (vs. #if-selecting code). &nbsp;I think one of the biggest lessons learned from Open MPI is that everyone&#39;s setup is different -- having the ability to mix and match various run-time options, while not widely used, is absolutely critical in some scenarios. &nbsp;So it might be good if --enable-large-system sets a bunch of default parameters that some sysadmins may still want/need to override.<br>
<br>- decision to run the modex: I haven&#39;t seen all of Ralph&#39;s work in this area, but I wonder if it&#39;s similar to the MPI handle parameter checks: it could be a multi-value MCA parameter, such as: &quot;never&quot;, &quot;always&quot;, &quot;when-ompi-determines-its-necessary&quot;, etc., where the last value can use multiple criteria to know if it&#39;s necessary to do a modex (e.g., job size, when spawn occurs, whether the &quot;pml&quot; [or other critical] MCA param[s] were specified, ...etc.). 
<div>
<div></div>
<div class="Wj3C7c"><br><br><br>On Jun 26, 2008, at 9:26 AM, Ralph H Castain wrote:<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Just to complete this thread...<br><br>Brian raised a very good point, so we identified it on the weekly telecon as<br>
a subject that really should be discussed at next week&#39;s technical meeting.<br>I think we can find a reasonable answer, but there are several ways it can<br>be done. So rather than doing our usual piecemeal approach to the solution,<br>
it makes sense to begin talking about a more holistic design for<br>accommodating both needs.<br><br>Thanks Brian for pointing out the bigger picture.<br>Ralph<br><br><br><br>On 6/24/08 8:22 AM, &quot;Brian W. Barrett&quot; &lt;<a href="mailto:brbarret@open-mpi.org" target="_blank">brbarret@open-mpi.org</a>&gt; wrote:<br>
<br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">yeah, that could be a problem, but it&#39;s such a minority case and we&#39;ve got<br>to draw the line somewhere.<br>
<br>Of course, it seems like this is a never ending battle between two<br>opposing forces... &nbsp;The desire to do the &quot;right thing&quot; all the time at<br>small and medium scale and the desire to scale out to the &quot;big thing&quot;.<br>
It seems like in the quest to kill off the modex, we&#39;ve run into these<br>pretty often.<br><br>The modex doesn&#39;t hurt us at small scale (indeed, we&#39;re probably ok with<br>the routed communication pattern up to 512 nodes or so if we don&#39;t do<br>
anything stupid, maybe further). &nbsp;Is it time to admit defeat in this<br>argument and have a configure option that turns off the modex (at the cost<br>of some of these correctness checks) for the large machines, but keeps<br>
things simple for the common case? &nbsp;I&#39;m sure there are other things where<br>this will come up, so perhaps a --enable-large-scale? &nbsp;Maybe it&#39;s a dumb<br>idea, but it seems like we&#39;ve made a lot of compromises lately around<br>
this, where no one ends up really happy with the solution :/.<br><br>Brian<br><br><br>On Tue, 24 Jun 2008, George Bosilca wrote:<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Brian hinted a possible bug in one of his replies. How does this work in the<br>case of dynamic processes? We can envision several scenarios, but lets take a<br>
simple: 2 jobs that get connected with connect/accept. One might publish the<br>PML name (simply because the -mca argument was on) and one might not?<br><br>george.<br><br>On Jun 24, 2008, at 8:28 AM, Jeff Squyres wrote:<br>
<br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Also sounds good to me.<br><br>Note that the most difficult part of the forward-looking plan is that we<br>
usually can&#39;t tell the difference between &quot;something failed to initialize&quot;<br>and &quot;you don&#39;t have support for feature X&quot;.<br><br>I like the general philosophy of: running out of the box always works just<br>
fine, but if you/the sysadmin is smart, you can get performance<br>improvements.<br><br><br>On Jun 23, 2008, at 4:18 PM, Shipman, Galen M. wrote:<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">I concur<br>- galen<br><br>On Jun 23, 2008, at 3:44 PM, Brian W. Barrett wrote:<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">That sounds like a reasonable plan to me.<br><br>Brian<br><br>On Mon, 23 Jun 2008, Ralph H Castain wrote:<br>
<br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Okay, so let&#39;s explore an alternative that preserves the support you are<br>seeking for the &quot;ignorant user&quot;, but doesn&#39;t penalize everyone else.<br>
What we<br>could do is simply set things up so that:<br><br>1. if -mca plm xyz is provided, then no modex data is added<br><br>2. if it is not provided, then only rank=0 inserts the data. All other<br>procs<br>simply check their own selection against the one given by rank=0<br>
<br>Now, if a knowledgeable user or sys admin specifies what to use for<br>their<br>system, we won&#39;t penalize their startup time. A user who doesn&#39;t know<br>what<br>to do gets to run, albeit less scalably on startup.<br>
<br>Looking forward from there, we can look to a day where failing to<br>initialize<br>something that exists on the system could be detected in some other<br>fashion,<br>letting the local proc abort since it would know that other procs that<br>
detected similar capabilities may well have selected that PML. For now,<br>though, this would solve the problem.<br><br>Make sense?<br>Ralph<br><br><br><br>On 6/23/08 1:31 PM, &quot;Brian W. Barrett&quot; &lt;<a href="mailto:brbarret@open-mpi.org" target="_blank">brbarret@open-mpi.org</a>&gt; wrote:<br>
<br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">The problem is that we default to OB1, but that&#39;s not the right choice<br>for<br>some platforms (like Pathscale / PSM), where there&#39;s a huge performance<br>
hit for using OB1. &nbsp;So we run into a situation where user installs Open<br>MPI, starts running, gets horrible performance, bad mouths Open MPI,<br>and<br>now we&#39;re in that game again. &nbsp;Yeah, the sys admin should know what to<br>
do,<br>but it doesn&#39;t always work that way.<br><br>Brian<br><br><br>On Mon, 23 Jun 2008, Ralph H Castain wrote:<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">My fault - I should be more precise in my language. ;-/<br><br>#1 is not adequate, IMHO, as it forces us to -always- do a modex. It<br>
seems<br>to me that a simpler solution to what you describe is for the user to<br>specify -mca pml ob1, or -mca pml cm. If the latter, then you could<br>deal<br>with the failed-to-initialize problem cleanly by having the proc<br>
directly<br>abort.<br><br>Again, sometimes I think we attempt to automate too many things. This<br>seems<br>like a pretty clear case where you know what you want - the sys admin,<br>if<br>nobody else, can certainly set that mca param in the default param<br>
file!<br><br>Otherwise, it seems to me that you are relying on the modex to detect<br>that<br>your proc failed to init the correct subsystem. I hate to force a<br>modex just<br>for that - if so, then perhaps this could again be a settable option<br>
to<br>avoid requiring non-scalable behavior for those of us who want<br>scalability?<br><br><br>On 6/23/08 1:21 PM, &quot;Brian W. Barrett&quot; &lt;brbarret@open-<a href="http://mpi.org/" target="_blank">mpi.org</a>&gt; wrote:<br>
<br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">The selection code was added because frequently high speed<br>interconnects<br>fail to initialize properly due to random stuff happening (yes,<br>
that&#39;s a<br>horrible statement, but true). &nbsp;We ran into a situation with some<br>really<br>flaky machines where most of the processes would chose CM, but a<br>couple<br>would fail to initialize the MTL and therefore chose OB1. &nbsp;This lead<br>
to a<br>hang situation, which is the worst of the worst.<br><br>I think #1 is adequate, although it doesn&#39;t handle spawn particularly<br>well. &nbsp;And spawn is generally used in environments where such network<br>mismatches are most likely to occur.<br>
<br>Brian<br><br><br>On Mon, 23 Jun 2008, Ralph H Castain wrote:<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Since my goal is to eliminate the modex completely for managed<br>installations, could you give me a brief understanding of this<br>
eventual PML<br>selection logic? It would help to hear an example of how and why<br>different<br>procs could get different answers - and why we would want to allow<br>them to<br>do so.<br><br>Thanks<br>Ralph<br><br><br><br>
On 6/23/08 11:59 AM, &quot;Aurélien Bouteiller&quot; &lt;<a href="mailto:bouteill@eecs.utk.edu" target="_blank">bouteill@eecs.utk.edu</a>&gt;<br>wrote:<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">The first approach sounds fair enough to me. We should avoid 2 and<br>3<br>as the pml selection mechanism used to be<br>
more complex before we reduced it to accommodate a major design bug<br>in<br>the BTL selection process. When using the complete PML selection,<br>BTL<br>would be initialized several times, leading to a variety of bugs.<br>
Eventually the PML selection should return to its old self, when<br>the<br>BTL bug gets fixed.<br><br>Aurelien<br><br>Le 23 juin 08 à 12:36, Ralph H Castain a écrit :<br><br>
<blockquote class="gmail_quote" style="PADDING-LEFT: 1ex; MARGIN: 0px 0px 0px 0.8ex; BORDER-LEFT: #ccc 1px solid">Yo all<br><br>I&#39;ve been doing further research into the modex and came across<br>something I<br>don&#39;t fully understand. It seems we have each process insert into<br>
the modex<br>the name of the PML module that it selected. Once the modex has<br>exchanged<br>that info, it then loops across all procs in the job to check<br>their<br>selection, and aborts if any proc picked a different PML module.<br>
<br>All well and good...assuming that procs actually -can- choose<br>different PML<br>modules and hence create an &quot;abort&quot; scenario. However, if I look<br>inside the<br>PML&#39;s at their selection logic, I find that a proc can ONLY pick a<br>
module<br>other than ob1 if:<br><br>1. the user specifies the module to use via -mca pml xyz or by<br>using a<br>module specific mca param to adjust its priority. In this case,<br>since the<br>mca param is propagated, ALL procs have no choice but to pick that<br>
same<br>module, so that can&#39;t cause us to abort (we will have already<br>returned an<br>error and aborted if the specified module can&#39;t run).<br><br>2. the pml/cm module detects that an MTL module was selected, and<br>
that it is<br>other than &quot;psm&quot;. In this case, the CM module will be selected<br>because its<br>default priority is higher than that of OB1.<br><br>In looking deeper into the MTL selection logic, it appears to me<br>
that you<br>either have the required capability or you don&#39;t. I can see that<br>in<br>some<br>environments (e.g., rsh across unmanaged collections of machines),<br>it might<br>be possible for someone to launch across a set of machines where<br>
some do and<br>some don&#39;t have the required support. However, in all other cases,<br>this will<br>be homogeneous across the system.<br><br>Given this analysis (and someone more familiar with the PML should<br>feel free<br>
to confirm or correct it), it seems to me that this could be<br>streamlined via<br>one or more means:<br><br>1. at the most, we could have rank=0 add the PML module name to<br>the<br>modex,<br>and other procs simply check it against their own and return an<br>
error if<br>they differ. This accomplishes the identical functionality to what<br>we have<br>today, but with much less info in the modex.<br><br>2. we could eliminate this info from the modex altogether by<br>requiring the<br>
user to specify the PML module if they want something other than<br>the<br>default<br>OB1. In this case, there can be no confusion over what each proc<br>is<br>to use.<br>The CM module will attempt to init the MTL - if it cannot do so,<br>
then the<br>job will return the correct error and tell the user that CM/MTL<br>support is<br>unavailable.<br><br>3. we could again eliminate the info by not inserting it into the<br>modex if<br>(a) the default PML module is selected, or (b) the user specified<br>
the PML<br>module to be used. In the first case, each proc can simply check<br>to<br>see if<br>they picked the default - if not, then we can insert the info to<br>indicate<br>the difference. Thus, in the &quot;standard&quot; case, no info will be<br>
inserted.<br><br>In the second case, we will already get an error if the specified<br>PML module<br>could not be used. Hence, the modex check provides no additional<br>info or<br>value.<br><br>I understand the motivation to support automation. However, in<br>
this<br>case,<br>the automation actually doesn&#39;t seem to buy us very much, and it<br>isn&#39;t<br>coming &quot;free&quot;. So perhaps some change in how this is done would be<br>in order?<br><br>Ralph<br><br><br><br>_______________________________________________<br>
devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
<br><br></blockquote>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
<br><br></blockquote>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
<br><br></blockquote>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br><br>-- <br>Jeff Squyres<br>Cisco Systems<br><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br></blockquote>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</blockquote><br><br>-- <br>Jeff Squyres<br>Cisco Systems<br><br><br>_______________________________________________<br>devel mailing list<br><a href="mailto:devel@open-mpi.org" target="_blank">devel@open-mpi.org</a><br><a href="http://www.open-mpi.org/mailman/listinfo.cgi/devel" target="_blank">http://www.open-mpi.org/mailman/listinfo.cgi/devel</a><br>
</div></div></blockquote></div><br>

